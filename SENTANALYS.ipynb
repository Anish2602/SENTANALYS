{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries"
      ],
      "metadata": {
        "id": "xwLEFdmjSwyc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D5Qpaj7ROahE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LOADING AND PROCESSING DATA\n"
      ],
      "metadata": {
        "id": "DA-G4-jcOw3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/sentiment-analysis.csv',sep=', ')\n",
        "data.columns = data.columns.str.replace('\"', '')\n",
        "data = data.dropna()  # Remove rows with missing values\n",
        "data['Text'] = data['Text'].astype(str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFX90jGaOtMn",
        "outputId": "384899a4-6c2b-4969-b281-aebd9efe60f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-9cd366c373e0>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  data = pd.read_csv('/content/sentiment-analysis.csv',sep=', ')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ENCODE SENTIMENTAL VALUES\n"
      ],
      "metadata": {
        "id": "oR7aCQsMSvJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "data['Sentiment'] = le.fit_transform(data['Sentiment'])"
      ],
      "metadata": {
        "id": "NLQS8Nz8O1VY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SPLITTING DATASET INTO TRAINING AND TESTING\n"
      ],
      "metadata": {
        "id": "uRcvh6NRStxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data['Text']\n",
        "y = data['Sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "Mc78mg4FO3xn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TOKENIZE AND PREPARE SEQUENCES\n"
      ],
      "metadata": {
        "id": "rXg8mpdYSsTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 10000  # Maximum number of words in your vocabulary\n",
        "max_len = 512  # Maximum length of input sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)"
      ],
      "metadata": {
        "id": "iSamEzmYO5-I"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BUILDING LSTM MODEL\n"
      ],
      "metadata": {
        "id": "2xpfCqwNSqap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100  # Dimension of word embeddings\n",
        "lstm_units = 512  # Number of LSTM units\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len))\n",
        "model.add(LSTM(units=lstm_units, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train_pad, y_train, epochs=25, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uw5E8FBUO-3D",
        "outputId": "24a14438-c62c-4a22-9225-307dc25db011"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "2/2 [==============================] - 35s 11s/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 2/25\n",
            "2/2 [==============================] - 24s 10s/step - loss: 0.6859 - accuracy: 0.5789\n",
            "Epoch 3/25\n",
            "2/2 [==============================] - 24s 10s/step - loss: 0.6763 - accuracy: 0.6974\n",
            "Epoch 4/25\n",
            "2/2 [==============================] - 25s 11s/step - loss: 0.6604 - accuracy: 0.8947\n",
            "Epoch 5/25\n",
            "2/2 [==============================] - 24s 10s/step - loss: 0.6335 - accuracy: 0.7632\n",
            "Epoch 6/25\n",
            "2/2 [==============================] - 22s 8s/step - loss: 0.5825 - accuracy: 0.8026\n",
            "Epoch 7/25\n",
            "2/2 [==============================] - 24s 9s/step - loss: 1.4725 - accuracy: 0.5263\n",
            "Epoch 8/25\n",
            "2/2 [==============================] - 24s 10s/step - loss: 2.7441 - accuracy: 0.5000\n",
            "Epoch 9/25\n",
            "2/2 [==============================] - 23s 10s/step - loss: 1.1388 - accuracy: 0.5000\n",
            "Epoch 10/25\n",
            "2/2 [==============================] - 25s 10s/step - loss: 0.5049 - accuracy: 0.9211\n",
            "Epoch 11/25\n",
            "2/2 [==============================] - 23s 9s/step - loss: 0.5102 - accuracy: 0.9737\n",
            "Epoch 12/25\n",
            "2/2 [==============================] - 22s 8s/step - loss: 0.5110 - accuracy: 0.9868\n",
            "Epoch 13/25\n",
            "2/2 [==============================] - 24s 10s/step - loss: 0.5138 - accuracy: 0.9868\n",
            "Epoch 14/25\n",
            "2/2 [==============================] - 23s 10s/step - loss: 0.5084 - accuracy: 0.9868\n",
            "Epoch 15/25\n",
            "2/2 [==============================] - 24s 10s/step - loss: 0.5005 - accuracy: 0.9868\n",
            "Epoch 16/25\n",
            "2/2 [==============================] - 23s 9s/step - loss: 0.4880 - accuracy: 0.9868\n",
            "Epoch 17/25\n",
            "2/2 [==============================] - 23s 8s/step - loss: 0.4718 - accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "2/2 [==============================] - 24s 10s/step - loss: 0.4526 - accuracy: 0.9868\n",
            "Epoch 19/25\n",
            "2/2 [==============================] - 23s 10s/step - loss: 0.4278 - accuracy: 0.9868\n",
            "Epoch 20/25\n",
            "2/2 [==============================] - 23s 10s/step - loss: 0.4044 - accuracy: 0.9868\n",
            "Epoch 21/25\n",
            "2/2 [==============================] - 23s 9s/step - loss: 0.3761 - accuracy: 0.9868\n",
            "Epoch 22/25\n",
            "2/2 [==============================] - 23s 8s/step - loss: 0.3457 - accuracy: 0.9868\n",
            "Epoch 23/25\n",
            "2/2 [==============================] - 24s 10s/step - loss: 0.3140 - accuracy: 0.9868\n",
            "Epoch 24/25\n",
            "2/2 [==============================] - 23s 10s/step - loss: 0.2823 - accuracy: 0.9868\n",
            "Epoch 25/25\n",
            "2/2 [==============================] - 25s 10s/step - loss: 0.2532 - accuracy: 0.9868\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d4f537b56c0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PREDICTIING SENTIMENT VALUES\n"
      ],
      "metadata": {
        "id": "m7auGmumSde3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_probs = model.predict(X_test_pad)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDmDVqfiPE7C",
        "outputId": "c216f7b8-6fb7-425b-8c0b-0a049a51cab7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      1.00      0.62         5\n",
            "           1       1.00      0.60      0.75        15\n",
            "\n",
            "    accuracy                           0.70        20\n",
            "   macro avg       0.73      0.80      0.69        20\n",
            "weighted avg       0.86      0.70      0.72        20\n",
            "\n",
            "Confusion Matrix:\n",
            " [[5 0]\n",
            " [6 9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VISUALIZE CONFUSION MARTIX\n"
      ],
      "metadata": {
        "id": "SH_HRvjQSlt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IxbO11MkSkW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STORE PREDICTIONS\n"
      ],
      "metadata": {
        "id": "DS32CARwSnjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = pd.DataFrame({'Text': X_test, 'Predicted_Sentiment': le.inverse_transform(y_pred)})\n",
        "predictions.to_csv('predictions.csv', index=False)  # Replace with desired file path\n",
        "\n",
        "print(\"Predictions:\\n\", predictions.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9ExvBEbSWyL",
        "outputId": "8aff79c7-1a6a-42a2-e83e-646bda01369b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions:\n",
            "                                                  Text Predicted_Sentiment\n",
            "80                     \"\"\"The service was terrible.\"\"            Negative\n",
            "77  \"\"\"This song always puts me in a nostalgic moo...            Positive\n",
            "73  \"\"\"The customer service at this store is outst...            Negative\n",
            "94  \"\"\"Their website is so confusing and poorly de...            Negative\n",
            "33  \"\"\"This restaurant has the most delicious food...            Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JZJby45uSZyx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}